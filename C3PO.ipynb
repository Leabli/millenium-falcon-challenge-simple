{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "class C3PO:\n",
    "    def __init__(self, millenniumFalconJsonFilePath):\n",
    "        with open(millenniumFalconJsonFilePath, 'r') as f:\n",
    "            self.millennium_falcon_data = json.load(f)\n",
    "        self.autonomy = self.millennium_falcon_data[\"autonomy\"]\n",
    "        self.routes = self.millennium_falcon_data[\"routes\"]\n",
    "        \n",
    "        self.graph = defaultdict(list)\n",
    "        for route in self.routes:\n",
    "            origin = route[\"origin\"]\n",
    "            destination = route[\"destination\"]\n",
    "            travelTime = route[\"travelTime\"]\n",
    "            self.graph[origin].append((destination, travelTime))\n",
    "            self.graph[destination].append((origin, travelTime))\n",
    "\n",
    "        for node in self.graph:\n",
    "            self.graph[node].append((node, 0))\n",
    "    \n",
    "    def giveMeTheOdds(self, empireJsonFilePath):\n",
    "        with open(empireJsonFilePath, 'r') as f:\n",
    "            self.empire_data = json.load(f)\n",
    "        countdown = self.empire_data[\"countdown\"]\n",
    "        bounty_hunters = self.empire_data[\"bounty_hunters\"]\n",
    "        \n",
    "        self.bounty_hunters_plan = defaultdict(list)\n",
    "        for bh in bounty_hunters:\n",
    "            planet = bh[\"planet\"]\n",
    "            day = bh[\"day\"]\n",
    "            self.bounty_hunters_plan[planet].append(day)\n",
    "        \n",
    "        start_planet = \"Tatooine\"\n",
    "        end_planet = \"Endor\"\n",
    " \n",
    "        dp = defaultdict(lambda: float('inf'))\n",
    "        dp[(start_planet, 0)] = 0.0\n",
    "        \n",
    "        # Queue with (current planet, current day, current capture encounters, remaining autonomy)\n",
    "        queue = deque([(start_planet, 0, 0, self.autonomy)])\n",
    "\n",
    "        way_to_endor = []\n",
    "        while queue:\n",
    "            # print('Queue is:', list(queue))\n",
    "            current_planet, current_day, current_encounters, remaining_autonomy = queue.popleft()\n",
    "            # print(f\"Exploring: {current_planet} on day {current_day} with {current_encounters} encounters and {remaining_autonomy} autonomy left\")\n",
    "  \n",
    "            if current_planet == end_planet and current_day <= countdown:\n",
    "                way_to_endor.append((current_planet, current_day, current_encounters, remaining_autonomy))\n",
    "                # print(f\"Reached Endor on day {current_day} with probability {round(1 - current_probability, 2)}\")\n",
    "                continue\n",
    "                    \n",
    "            for neighbor, travel_time in self.graph[current_planet]:\n",
    "                # print(f\"Considering move to: {neighbor} with travel time: {travel_time}\")\n",
    "                if current_day + travel_time <= countdown:\n",
    "                    # print(f\"Can reach {neighbor} by day {current_day + travel_time} within countdown {countdown}\")\n",
    "                    new_day = current_day + travel_time\n",
    "                    new_encounters = current_encounters\n",
    "                    new_remaining_autonomy = remaining_autonomy - travel_time\n",
    "                    \n",
    "                    if neighbor in self.bounty_hunters_plan and new_day in self.bounty_hunters_plan[neighbor]:\n",
    "                        new_encounters += 1\n",
    "                        # print(f\"Encounter with bounty hunters on {neighbor} on day {new_day}. Total encounters: {new_encounters}\")\n",
    "                    \n",
    "                    if neighbor == current_planet:\n",
    "                        new_day += 1\n",
    "                        new_remaining_autonomy = self.autonomy\n",
    "                        # print(f\"Refueling on the same planet {current_planet}, reset autonomy to {self.autonomy}\")\n",
    "                    \n",
    "                    if new_remaining_autonomy == 0:\n",
    "                        # print(f\"No more fuel\")\n",
    "                        new_day += 1\n",
    "                        new_remaining_autonomy = self.autonomy\n",
    "                        if neighbor in self.bounty_hunters_plan and (new_day) in self.bounty_hunters_plan[neighbor]:\n",
    "                            new_encounters += 1\n",
    "                            # print(f\"Encounter with bounty hunters during refuel on {neighbor} on day {new_day}. Total encounters: {new_encounters}\")\n",
    "                    \n",
    "                    if dp[(neighbor, new_day)] >= new_encounters:\n",
    "                        dp[(neighbor, new_day)] = new_encounters\n",
    "                        queue.append((neighbor, new_day, new_encounters, new_remaining_autonomy))\n",
    "                        # print(f\"Added to queue: {neighbor} on day {new_day} with {new_encounters} encounters and {new_remaining_autonomy} autonomy left\")\n",
    "                        # print(neighbor, new_day, new_encounters, new_remaining_autonomy)\n",
    "\n",
    "        if not way_to_endor:\n",
    "            return 0.0\n",
    "        else : \n",
    "            best_path = min(way_to_endor, key=lambda x: x[2])\n",
    "            return 1 - round(1 - (0.9 ** best_path[2]), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1 : 0.0 Correct\n",
      "\n",
      "Example 2 : 0.81 Correct\n",
      "\n",
      "Example 3 : 0.9 Correct\n",
      "\n",
      "Example 4 : 1.0 Correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_directory = \"examples/\"\n",
    "\n",
    "number_of_examples = 4\n",
    "expected_result = [0, 0.81, 0.9, 1]\n",
    "\n",
    "for i in range(1, number_of_examples + 1):\n",
    "    example_sub_dir = example_directory + \"example\" + str(i) + \"/\" \n",
    "    millennium_falcon_json_path = example_sub_dir + \"millennium-falcon.json\"\n",
    "    empire_json_path = example_sub_dir + \"empire.json\"\n",
    "    c3po = C3PO(millennium_falcon_json_path)\n",
    "    odds = c3po.giveMeTheOdds(empire_json_path)\n",
    "    if odds == expected_result[i - 1]:\n",
    "        print(\"Example\", i, \":\", odds, \"Correct\")\n",
    "    else : \n",
    "        print(\"Example\", i, \":\", odds, \"Incorrect\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machineLearnig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
